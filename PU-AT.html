<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
  <link rel="icon" type="image/x-icon" href="images/YH.png" />
  <title>Panoramic image inpainting</title>
  <!--Import Google Icon Font-->

  <!--<link href="http://fonts.useso.com/icon?family=Material+Icons" rel="stylesheet">-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="css/main.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <!--Import jQuery before materialize.js-->
  <script type="text/javascript" src="js/jquery-3.0.0.min.js"></script>
  <script type="text/javascript" src="js/materialize.min.js"></script>
  <script type="text/javascript" src="js/main.js"></script>
  <style>
    body
    {
      font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    }
    .vertical-nav
    {
      margin: 0;
      position: fixed;
      width: 300px;
      /*background-color: #343131;*/
      min-height: 100%;
      background-image: url("images/vertical_Nov19.jpg");
      background-repeat: round;
    }

    .profile-block
    {
      position: relative;
      height: 300px;
      /*background-color: #324D5C;*/

    }
    .profile-block-sm
    {
      position: relative;
      height: 200px;
      /*background-color: #324D5C;*/

    }

    .profile
    {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      border-radius: 50%;
      margin-left: 30px;

      border: solid 5px #F4D03F;
    }

    .profile-sm
    {
      /*position: absolute;*/
      /*top: 50%;*/
      /*left: 50%;*/
      /*transform: translateX(50%);*/
      border-radius: 50%;
      margin: auto;

      border: solid 5px #F4D03F;
    }

    .logo-link
    {
      padding-left: 10px;
      padding-right: 10px;
    }
    .card-content
    {
      padding: 0 !important;
    }

    .card-title
    {
      background-color: #FBD8B0;
      padding: 12px;
    }

    p
    {
      line-height: 150%;
    }
    li
    {
      padding-bottom: 10px;
    }
    strong
    {
      font-weight: bolder;
    }
    .project-item
    {
    }
    .project-logo
    {
    }
    .authors{
      text-align: center;
      width: 100%;
      margin: auto;
      font-size: 12pt;
      padding-top: 20px;
      padding-bottom: 20px;
    }
    .author{
      font-weight: bold;
      display: inline;
      padding: 0 1em;
    }
    h3{
      font-size: xx-large;
      display: block;
      /*font-size: 1.5em;*/
      margin-block-start: 0.83em;
      margin-block-end: 0.83em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      font-weight: bold;
    }
    .bibtex {
      padding-left: 20px;
      font-family: Courier New, Courier, 'gandhi_sansregular', monospace;
      white-space: pre;
    }
    ul.marked {list-style-type: circle !important;}
    ul li::marker {
      color: darkslategrey;
      font-size: 1.5em;
    }
  </style>
</head>
<body>

<div class="">
  <div style="">
    <div class="container">
      <div class="">
        <div class="row">
          <div class="col s12 m12 l10 offset-l1">
            <div class="title">
              <h2 class="center" style="margin-top: 120px; font-size: 32pt">
               Point cloud sampling based on Transformer
              </h2>
              <!-- <p class="center" style="font-size: large"><a href="https://arxiv.org/abs/2002.03711">[ arxiv.org/abs/2002.03711 ]</a> -->
                <p class="center" style="font-size: large"><a href="https://github.com/Vencoders/PU-AT">[ Code ]</a>
            </div>
           <div class="authors">
<!-- 			  <div class="author"><a href="https://huzi96.github.io/">Yueyu Hu</a></div><br class="hide-on-med-and-up"> -->
              <div class="author">Li Yu {li.yu@nuist.edu.cn}</a></div><br class="hide-on-med-and-up">
              <div class="author">Jiafu Zhang {20211249472@nuist.edu.cn}</a></div><br class="hide-on-med-and-up">
            </div>
			<div class="abstract">
			  <h3 class="center">Abstract</h3>
			  <ul style="font-size: 13pt; text-align: justify">
			    <li>
			      <div>
			        <i class="material-icons tiny cyan-text">grade</i>
			        The Point cloud upsampling operation as a fundamental task in computer vision, has been widely studied. Point clouds obtained from real-world radar scans are often sparse and unevenly distributed, impacting their quality. Up-sampling operations effectively address this issue by enhancing point cloud quality. To tackle challenges such as structural information loss and low precision in up-sampling tasks, a novel 3D point cloud up-sampling method based on Transformers is proposed, aiming to explore the potential of Trans-formers in this domain. Initially, a two-step network is employed, transitioning from rough dense point cloud generation to point cloud refinement, with each sub-network focusing on specific objectives. The coarse generation network aims to increase point cloud resolution, utilizing multiple densely connected convolutional blocks to extract deep high-dimensional features. To efficiently explore the upsampling space of point clouds, an innovative integration of upsampling module with Transformer is introduced. While the rough generation of point clouds increases the number of points, correction of noise points is essential. In the refinement network, an adaptive refinement module is introduced, capable of autonomously aggregating structural information based on local point cloud characteristics. Extensive experimentation validates the superior performance of the proposed method in both quantitative and qualitative aspects compared to pre-vious approaches, demonstrating its remarkable efficacy.
			      </div>
			        </li>
			  </ul>
			</div>
            <div class="abstract">
              <h3 class="center">Highlights</h3>
              <ul style="font-size: 13pt; text-align: justify">
                <li>
                  <div>
                    <i class="material-icons tiny cyan-text">grade</i>
                    We propose a Transformer-based feature expansion module that can fully explore the latent feature space.
                  </div>
                    </li>
                <li>
                  <div>
                    <i class="material-icons tiny  cyan-text">grade</i>
                  We propose an adaptive refinement module that can adaptively correct outliers based on local geometric structures.
                  </div>
                    </li>
                <li>
                  <div>
                    <i class="material-icons tiny  cyan-text">grade</i>
                    Our method achieves better performance than the SOTA method on the synthetic dataset both qualitatively and quantitatively.
                  </div>
                     </li>
              </ul>
            </div>
            <div class="experiment">

              <div class="row">
                <h3 class="center">Network Architecture</h3>
                <div class="col l18 m18 s18">
                  <img src="images/PU-AT1.png" class="responsive-img">
                </div>

                <div class="col l12 m12 s12">
                  <p style="text-align: justify"><i class="material-icons tiny cyan-text">grade</i>The overall framework of our proposed method PU-AT, the given input point cloud undergoes the Point Generator to produce a coarse point cloud, which consists of three main components.
The Feature Extraction module thoroughly extracts multi-scale structural information of local geometries to obtain the latent code. 
Similar to prior works, we employ the Feature Expansion Module to upsample features in the latent feature space, as it provides a richer representation in high-dimensional feature space than 3D coordinate space. 
Finally, the Coordinate Reconstruction module is utilized to map the upsampled features back to reconstruct a dense point set in coordinate space. The coarse point cloud and the upsampled features are jointly inputted into the refinement module to obtain fine feature $F_R$, then we regress displacements, which are added to the coarse point cloud to obtain the final refined point cloud.
                </div>
              </div>
			  
             <div class="row">
                <h3 class="center">Results</h3>
                <div class="col l6 offset-l3 m8 offset-m2 s10 offset-s1">
                  <img src="images/PU-ATResult.png" class="responsive-img">
				          
                </div>
			
			
				  
              <div class="row">
                <div class="col l12 m12 s12">
                  <p><strong>Please check our paper for detail results.</strong></p>
                </div>
              </div>
            </div>

              <div class="row">
				  <h3 class="center">Citation</h3>
                <div class="col l12 m12 s12">
                  <p>
					

                 </p>
                </div>
              </div>
            </div>

            
            
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</body>
</html>

