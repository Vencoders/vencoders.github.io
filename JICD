<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
  <link rel="icon" type="image/x-icon" href="images/YH.png" />
  <title>JOINT END-TO-END IMAGE COMPRESSION AND DENOISING: LEVERAGING CONTRASTIVE LEARNING AND MULTI-SCALE SELF-ONNS</title>
  <!--Import Google Icon Font-->

  <!--<link href="http://fonts.useso.com/icon?family=Material+Icons" rel="stylesheet">-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="css/main.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <!--Import jQuery before materialize.js-->
  <script type="text/javascript" src="js/jquery-3.0.0.min.js"></script>
  <script type="text/javascript" src="js/materialize.min.js"></script>
  <script type="text/javascript" src="js/main.js"></script>
  <style>
    body
    {
      font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    }
    .vertical-nav
    {
      margin: 0;
      position: fixed;
      width: 300px;
      /*background-color: #343131;*/
      min-height: 100%;
      background-image: url("images/vertical_Nov19.jpg");
      background-repeat: round;
    }

    .profile-block
    {
      position: relative;
      height: 300px;
      /*background-color: #324D5C;*/

    }
    .profile-block-sm
    {
      position: relative;
      height: 200px;
      /*background-color: #324D5C;*/

    }

    .profile
    {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      border-radius: 50%;
      margin-left: 30px;

      border: solid 5px #F4D03F;
    }

    .profile-sm
    {
      /*position: absolute;*/
      /*top: 50%;*/
      /*left: 50%;*/
      /*transform: translateX(50%);*/
      border-radius: 50%;
      margin: auto;

      border: solid 5px #F4D03F;
    }

    .logo-link
    {
      padding-left: 10px;
      padding-right: 10px;
    }
    .card-content
    {
      padding: 0 !important;
    }

    .card-title
    {
      background-color: #FBD8B0;
      padding: 12px;
    }

    p
    {
      line-height: 150%;
    }
    li
    {
      padding-bottom: 10px;
    }
    strong
    {
      font-weight: bolder;
    }
    .project-item
    {
    }
    .project-logo
    {
    }
    .authors{
      text-align: center;
      width: 100%;
      margin: auto;
      font-size: 12pt;
      padding-top: 20px;
      padding-bottom: 20px;
    }
    .author{
      font-weight: bold;
      display: inline;
      padding: 0 1em;
    }
    h3{
      font-size: xx-large;
      display: block;
      /*font-size: 1.5em;*/
      margin-block-start: 0.83em;
      margin-block-end: 0.83em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      font-weight: bold;
    }
    .bibtex {
      padding-left: 20px;
      font-family: Courier New, Courier, 'gandhi_sansregular', monospace;
      white-space: pre;
    }
    ul.marked {list-style-type: circle !important;}
    ul li::marker {
      color: darkslategrey;
      font-size: 1.5em;
    }
  </style>
</head>
<body>

<div class="">
  <div style="">
    <div class="container">
      <div class="">
        <div class="row">
          <div class="col s12 m12 l10 offset-l1">
            <div class="title">
              <h2 class="center" style="margin-top: 120px; font-size: 32pt">
               JOINT END-TO-END IMAGE COMPRESSION AND DENOISING: LEVERAGING CONTRASTIVE LEARNING AND MULTI-SCALE SELF-ONNS
              </h2>
              <!-- <p class="center" style="font-size: large"><a href="https://arxiv.org/abs/2002.03711">[ arxiv.org/abs/2002.03711 ]</a> -->
                <p class="center" style="font-size: large"><a href="https://github.com/Vencoders/Joint-image-denoising-and-compression">[ Code ]</a>
            </div>
           <div class="authors">
<!-- 			  <div class="author"><a href="https://huzi96.github.io/">Yueyu Hu</a></div><br class="hide-on-med-and-up"> -->
              <div class="author">Yuxin Xie {202212210053@nuist.edu.cn}</a></div><br class="hide-on-med-and-up">
              <div class="author">Li Yu {li.yu@nuist.edu.cn}</a></div><br class="hide-on-med-and-up">
              <div class="author">Farhad Pakdaman {farhad.pakdaman@gmail.com)}</a></div><br class="hide-on-med-and-up">
              <div class="author">Moncef Gabbouj {moncef.gabbouj@tuni.fi}</a></div><br class="hide-on-med-and-up">
            </div>
			<div class="abstract">
			  <h3 class="center">Abstract</h3>
			  <ul style="font-size: 13pt; text-align: justify">
			    <li>
			      <div>
			        <i class="material-icons tiny cyan-text">grade</i>
			        Noisy images are a challenge to image compression algorithms due to the inherent difficulty of compressing noise. As noise cannot easily be discerned from image details, such as high-frequency signals, its presence leads to extra bits needed for compression. Since the emerging learned image compression paradigm enables end-to-end optimization of codecs, recent efforts were made to integrate denoising into the compression model, relying on clean image features to guide denoising. However, these methods exhibit suboptimal performance under high noise levels, lacking the capability to generalize across diverse noise types. In this paper, we propose a novel method integrating a multi-scale denoiser comprising of Self Organizing Operational Neural Networks, for joint image compression and denoising. We employ contrastive learning to boost the network ability to differentiate noise from high frequency signal components, by emphasizing the correlation between noisy and clean counterparts. Experimental results demonstrate the effectiveness of the proposed method both in ratedistortion performance, and codec speed, outperforming the current state-of-the-art.
			      </div>
			        </li>
			  </ul>
			</div>
            <div class="abstract">
              <h3 class="center">Highlights</h3>
              <ul style="font-size: 13pt; text-align: justify">
                <li>
                  <div>
                    <i class="material-icons tiny cyan-text">grade</i>
                    We propose a joint compression-denoising method, which uses contrastive learning and guiding loss, helping the model to better discern noise from details at encoding stage.
                  </div>
                    </li>
                <li>
                  <div>
                    <i class="material-icons tiny  cyan-text">grade</i>
                  We propose a denoiser module using multi-scale Self-ONN blocks and CBAM attention, which leverages the heterogeneity and enhanced non-linearity of operations to effectively handle images with various noise levels.
                  </div>
                    </li>
                <li>
                  <div>
                    <i class="material-icons tiny  cyan-text">grade</i>
                    Extensive experiments demonstrate that the proposed method outperforms the state-of-the-art, in rate-distortion performance, especially in dealing with high-level noise, while being faster.
                  </div>
                     </li>
              </ul>
            </div>
            <div class="experiment">

              <div class="row">
                <h3 class="center">Network Architecture</h3>
                <div class="col l12 m12 s12">
                  <img src="images/overviewjicd.png" class="responsive-img">
                </div>

                <div class="col l12 m12 s12">
                  <p style="text-align: justify"><i class="material-icons tiny cyan-text">grade</i>Overview of the proposed method, with a three-branch structure: the guidance branch supervises the denoising process, and the contrastive branch aids the model to discriminate noise from details. Denoised features are compressed with learned compression.
                  </p>
                </div>
              </div>
			  
             <div class="row">
                <h3 class="center">Results</h3>
                <div class="col l12 m12 s12">
                  <img src="images/visualizationjicd.png" class="responsive-img">
				          <img src="images/complexityjicd.png" class="responsive-img">
                </div>
			
			
				  
              <div class="row">
                <div class="col l12 m12 s12">
                  <p><strong>Please check our paper for detail results.</strong></p>
                </div>
              </div>
            </div>

              <div class="row">
				  <h3 class="center">Citation</h3>
                  @INPROCEEDINGS{10446469,
  author={Yuxin Xie, Li Yu, and Pakdaman, Farhad and Gabbouj, Moncef},
  booktitle={ICIP 2024 - 2024 IEEE International Conference on Image Processing (ICIP)},
  title={JOINT END-TO-END IMAGE COMPRESSION AND DENOISING: LEVERAGING CONTRASTIVE LEARNING AND MULTI-SCALE SELF-ONNS},
  year={2024},
  doi={}

                <div class="col l12 m12 s12">
                  <p>
					

                 </p>
                </div>
              </div>
            </div>

            
            
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</body>
</html>
