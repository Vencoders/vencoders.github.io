<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
  <link rel="icon" type="image/x-icon" href="images/YH.png" />
  <title>natural transfer</title>
  <!--Import Google Icon Font-->

  <!--<link href="http://fonts.useso.com/icon?family=Material+Icons" rel="stylesheet">-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="css/main.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <!--Import jQuery before materialize.js-->
  <script type="text/javascript" src="js/jquery-3.0.0.min.js"></script>
  <script type="text/javascript" src="js/materialize.min.js"></script>
  <script type="text/javascript" src="js/main.js"></script>
  <style>
    body
    {
      font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    }
    .vertical-nav
    {
      margin: 0;
      position: fixed;
      width: 300px;
      /*background-color: #343131;*/
      min-height: 100%;
      background-image: url("images/vertical_Nov19.jpg");
      background-repeat: round;
    }

    .profile-block
    {
      position: relative;
      height: 300px;
      /*background-color: #324D5C;*/

    }
    .profile-block-sm
    {
      position: relative;
      height: 200px;
      /*background-color: #324D5C;*/

    }

    .profile
    {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      border-radius: 50%;
      margin-left: 30px;

      border: solid 5px #F4D03F;
    }

    .profile-sm
    {
      /*position: absolute;*/
      /*top: 50%;*/
      /*left: 50%;*/
      /*transform: translateX(50%);*/
      border-radius: 50%;
      margin: auto;

      border: solid 5px #F4D03F;
    }

    .logo-link
    {
      padding-left: 10px;
      padding-right: 10px;
    }
    .card-content
    {
      padding: 0 !important;
    }

    .card-title
    {
      background-color: #FBD8B0;
      padding: 12px;
    }

    p
    {
      line-height: 150%;
    }
    li
    {
      padding-bottom: 10px;
    }
    strong
    {
      font-weight: bolder;
    }
    .project-item
    {
    }
    .project-logo
    {
    }
    .authors{
      text-align: center;
      width: 100%;
      margin: auto;
      font-size: 12pt;
      padding-top: 20px;
      padding-bottom: 20px;
    }
    .author{
      font-weight: bold;
      display: inline;
      padding: 0 1em;
    }
    h3{
      font-size: xx-large;
      display: block;
      /*font-size: 1.5em;*/
      margin-block-start: 0.83em;
      margin-block-end: 0.83em;
      margin-inline-start: 0px;
      margin-inline-end: 0px;
      font-weight: bold;
    }
    .bibtex {
      padding-left: 20px;
      font-family: Courier New, Courier, 'gandhi_sansregular', monospace;
      white-space: pre;
    }
    ul.marked {list-style-type: circle !important;}
    ul li::marker {
      color: darkslategrey;
      font-size: 1.5em;
    }
  </style>
</head>
<body>

<div class="">
  <div style="">
    <div class="container">
      <div class="">
        <div class="row">
          <div class="col s12 m12 l10 offset-l1">
            <div class="title">
              <h2 class="center" style="margin-top: 120px; font-size: 32pt">
                Neural texture transfer assisted video coding with adaptive up-sampling
              </h2>
              <!-- <p class="center" style="font-size: large"><a href="https://arxiv.org/abs/2002.03711">[ arxiv.org/abs/2002.03711 ]</a> -->
                <p class="center" style="font-size: large"><a href="https://github.com/Vencoders/Ref-frame-encode">[ Code ]</a>
            </div>
           <div class="authors">
<!-- 			  <div class="author"><a href="https://huzi96.github.io/">Yueyu Hu</a></div><br class="hide-on-med-and-up"> -->
              <div class="author">Li Yu</a></div><br class="hide-on-med-and-up">
              <div class="author">Wenshuai Chang</a></div><br class="hide-on-med-and-up">
              <div class="author">Weize Quan</a></div><br class="hide-on-med-and-up">
              <div class="author">Jimin Xiao</a></div><br class="hide-on-med-and-up">
			  <div class="author">Dong-Ming Yan</a></div><br class="hide-on-med-and-up">
			  <div class="author">Moncef Gabbouj</a></div><br class="hide-on-med-and-up">
            </div>
			<div class="abstract">
			  <h3 class="center">Abstract</h3>
			  <ul style="font-size: 13pt; text-align: justify">
			    <li>
			      <div>
			        <i class="material-icons tiny cyan-text">grade</i>
			        Deep learning techniques have been extensively investigated for the purpose of further increasing the efficiency of traditional video compression. Some deep learning techniques for down/up-sampling-based video coding were found to be especially effective when the bandwidth or storage is limited. Existing works mainly differ in the super-resolution models used. Some works simply use a single image super-resolution model, ignoring the rich information in the correlation between video frames, while others explore the correlation between frames by simply concatenating the features across adjacent frames. This, however, may fail when the textures are not well aligned. In this paper, we propose to utilize neural texture transfer which exploits the semantic correlation between frames and is able to explore the correlated information even when the textures are not aligned. Meanwhile, an adaptive group of pictures (GOP) method is proposed to automatically decide whether a frame should be down-sampled or not. Experimental results show that the proposed method outperforms the standard HEVC and state-of-the-art methods under different compression configurations. When compared to standard HEVC, the BD-rate (PSNR) and BD-rate (SSIM) of the proposed method are up to -19.1% and -26.5%, respectively. 
			      </div>
			        </li>
			  </ul>
			</div>
            <div class="abstract">
              <h3 class="center">Highlights</h3>
              <ul style="font-size: 13pt; text-align: justify">
                <li>
                  <div>
                    <i class="material-icons tiny cyan-text">grade</i>
                    We introduce reference-based SR in down/up-sampling based video coding method, where target and reference images are not required to be texture-aligned as required in existing methods.
                  </div>
                    </li>
                <li>
                  <div>
                    <i class="material-icons tiny  cyan-text">grade</i>
                    We proposed an adaptive group of pictures (GOP) method to automatically decide the adaptive sampling scheme.
                  </div>
                    </li>
                <li>
                  <div>
                    <i class="material-icons tiny  cyan-text">grade</i>
                   The neural texture transfer model for reference-based SR produces realistic up-sampled frame at the decoding end.
                  </div>
                     </li>
              </ul>
            </div>
            <div class="experiment">

              <div class="row">
                <h3 class="center">Texture Transfer based Frame SR Model</h3>
                <div class="col l12 m12 s12">
                  <img src="images/frame.png" class="responsive-img">
                </div>

                <div class="col l12 m12 s12">
                  <p style="text-align: justify"><i class="material-icons tiny cyan-text">grade</i> Diagram of the proposed methods (in gray boxes), integrated into a typical video encoding/decoding flow. The video frames are adaptively divided into reference frames (RF) and non-reference frames (NF) by the proposed adaptive GOP method. The RFs are encoded at full resolution, while NFs are encoded at reduced resolution using the standard HEVC encoder. At the decoder, all frames are decoded by the standard HEVC decoder first. Then, the decoded full-resolution frame ùëÖùêπùê∑ is used to facilitate the super-resolution of low-resolution ùëÅùêπùêøùëÖ‚Üëùêusing the proposed neural texture transfer network.  
                  </p>
                </div>
              </div>
			  
              <div class="row">
                <h3 class="center">Results</h3>
                <div class="col l12 m12 s12">
                  <img src="images/frame1.png" class="responsive-img">
				  <img src="images/frame2.png" class="responsive-img">
                </div>
				
              <div class="row">
                <div class="col l12 m12 s12">
                  <p><strong>Please check our paper for detail results.</strong></p>
                </div>
              </div>
            </div>

              <div class="row">
				  <h3 class="center">Citation</h3>
                <div class="col l12 m12 s12">
                  <p>@article{yu2022neural,<br>
					&nbsp;title={Neural texture transfer assisted video coding with adaptive up-sampling},<br>
				    &nbsp;author={Yu, Li and Chang, Wenshuai and Quan, Weize and Xiao, Jimin and Yan, Dong-Ming and Gabbouj, Moncef},<br>
				    &nbsp;journal={Signal Processing: Image Communication},
				    &nbsp;volume={107},<br>
				    &nbsp;pages={116754},<br>
				    &nbsp;year={2022},<br>
				    &nbsp;publisher={Elsevier}<br>
                 }</p>
                </div>
              </div>
            </div>

            
            
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</body>
</html>
